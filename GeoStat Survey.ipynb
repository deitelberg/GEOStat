{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyreadstat as prs\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import config as c\n",
    "\n",
    "stataDirs = [c.db2018, \n",
    "             c.db2017, \n",
    "             c.db2016, \n",
    "             c.db2015, \n",
    "             c.db2014, \n",
    "             c.db2013, \n",
    "             c.db2012, \n",
    "             c.db2011, \n",
    "             c.db2010, \n",
    "             c.db2009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(c.db2018)\n",
    "for f in sorted(os.listdir(c.db2018)):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stataDir in stataDirs:\n",
    "    print('\\n')\n",
    "    print(stataDir)\n",
    "    cols = 0\n",
    "    savs = 0\n",
    "    for f in os.listdir(stataDir):\n",
    "        if 'deadmen' not in f:\n",
    "            continue\n",
    "        filePath = os.path.join(stataDir, f)\n",
    "        print(f)\n",
    "        df, meta = prs.read_sav(filePath)#, apply_value_formats=True, formats_as_category=True)\n",
    "        object_methods = [meta for meta in dir(object) if callable(getattr(object, meta))]\n",
    "        print(df.head())\n",
    "        #print('count: {} -- {}'.format(len(df.RegNo.unique()), np.sort(df.RegNo.unique()).astype(int)))\n",
    "        print('number_rows: {}'.format(meta.number_rows))\n",
    "        print('column_names, n = {}'.format(len(meta.column_names), meta.column_names))\n",
    "        print('column_labels, n = {}\\n'.format(len(meta.column_labels), meta.column_labels))\n",
    "        colLabels = meta.column_labels\n",
    "        for l in colLabels:\n",
    "            print(l)\n",
    "    break\n",
    "    print('total savs = {}'.format(savs))\n",
    "    print('total cols = {}'.format(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all files in a single year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stataDir in stataDirs:\n",
    "    n=1\n",
    "    #print('\\n{}'.format(stataDir))\n",
    "    for f in os.listdir(stataDir):\n",
    "        #if 'deadmen' not in f:\n",
    "        #    continue\n",
    "        filePath = os.path.join(stataDir, f)\n",
    "        print('#{} {:>5s} {}'.format(n, '', f))\n",
    "        \n",
    "        df, meta = prs.read_sav(filePath)#, apply_value_formats=True, formats_as_category=True)\n",
    "        object_methods = [meta for meta in dir(object) if callable(getattr(object, meta))]\n",
    "        print('{}'.format('-'*40))\n",
    "        #print(df.info())\n",
    "        #print('{}'.format('-'*40))\n",
    "        print('Rows: {}  Cols: {}'.format(df.shape[0], df.shape[1]))\n",
    "\n",
    "        col_names = meta.column_names\n",
    "        col_labels = meta.column_labels\n",
    "        col_names_labels = dict(zip(col_names, col_labels))\n",
    "        print('Names: {}  Labels: {}'.format(len(col_names), len(col_labels)))\n",
    "        i = 1\n",
    "        for name, label in col_names_labels.items():\n",
    "            unique_cnt = len(df[name].unique())\n",
    "            print('{:<3} {:<4} {:<20}  {}'.format(i, unique_cnt, name, label))\n",
    "            i+=1\n",
    "    \n",
    "        n+=1\n",
    "        #vvl_dict = meta.variable_value_labels\n",
    "        #for k1, v1 in vvl_dict.items():\n",
    "        #    print('  {}  (value type: {})'.format(k1, type(v1)))\n",
    "        #    for k2, v2 in v1.items():\n",
    "        #        print('    {}  {}'.format(k2, v2))\n",
    "            \n",
    "        print('{}\\n'.format('-'*80))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare a single file across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_file = 'sysschedule.sav'\n",
    "for stataDir in stataDirs:\n",
    "    year = os.path.basename(stataDir)[:4]\n",
    "    for f in os.listdir(stataDir):\n",
    "        if specific_file not in f:\n",
    "            continue\n",
    "            \n",
    "        filePath = os.path.join(stataDir, f)\n",
    "        print('{:<5} {}'.format(year, f))\n",
    "        \n",
    "        df, meta = prs.read_sav(filePath)#, apply_value_formats=True, formats_as_category=True)\n",
    "        print(df.head())\n",
    "        object_methods = [meta for meta in dir(object) if callable(getattr(object, meta))]\n",
    "        print('{}'.format('-'*40))\n",
    "        print('Rows: {}  Cols: {}'.format(df.shape[0], df.shape[1]))\n",
    "\n",
    "        col_names = meta.column_names\n",
    "        col_labels = meta.column_labels\n",
    "        col_names_labels = dict(zip(col_names, col_labels))\n",
    "        print('Names: {}  Labels: {}'.format(len(col_names), len(col_labels)))\n",
    "        i = 1\n",
    "        for name, label in col_names_labels.items():\n",
    "            unique_cnt = len(df[name].unique())\n",
    "            print('{:<3} {:<6} {:<20}  {}'.format(i, unique_cnt, name, label))\n",
    "            i+=1\n",
    "        \n",
    "        print('\\n---- Fields with codes, and their lookup values ---')\n",
    "        vvl_dict = meta.variable_value_labels\n",
    "        for k1, v1 in vvl_dict.items():\n",
    "            print('{:<5}'.format(k1, type(v1)))\n",
    "            for k2, v2 in v1.items():\n",
    "                print('  {:<5} {}'.format(k2, v2))\n",
    "            \n",
    "        print('{}\\n'.format('-'*80))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check number of unique regions and their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "specific_file = 'sysschedule.sav'\n",
    "for stataDir in stataDirs:\n",
    "    year = os.path.basename(stataDir)[:4]\n",
    "    for f in os.listdir(stataDir):\n",
    "        if specific_file not in f:\n",
    "            continue\n",
    "            \n",
    "        filePath = os.path.join(stataDir, f)\n",
    "        print('{:<5} {}'.format(year, f))\n",
    "        \n",
    "        df, meta = prs.read_sav(filePath)#, apply_value_formats=True, formats_as_category=True)\n",
    "        object_methods = [meta for meta in dir(object) if callable(getattr(object, meta))]\n",
    "        print('Rows: {}  Cols: {}'.format(df.shape[0], df.shape[1]))\n",
    "        \n",
    "        regions = np.sort(df.RegNo.unique()).astype(int)\n",
    "        print('Count: {} -- Region Values: {}'.format(len(regions), regions))\n",
    "        print('{}\\n'.format('-'*80))\n",
    "    \n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all questions (long field names) for 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_year = 2018\n",
    "i = 1\n",
    "outCsv = os.path.join(c.outDir, 'fields.csv')\n",
    "sep = '\\t'\n",
    "\n",
    "try: os.remove(outCsv)\n",
    "except: Path(outCsv).touch()\n",
    "\n",
    "for stataDir in stataDirs:\n",
    "    year = os.path.basename(stataDir)[:4]\n",
    "    if int(year) != search_year:\n",
    "        continue\n",
    "    print('yr: {}   I want: {}'.format(year, search_year))\n",
    "\n",
    "    for f in sorted(os.listdir(stataDir)):\n",
    "        #if specific_file not in f:\n",
    "        #    continue\n",
    "        fname = f.strip('.sav')\n",
    "        filePath = os.path.join(stataDir, f)\n",
    "        #print('{:<5} {}'.format(year, f))\n",
    "        \n",
    "        df, meta = prs.read_sav(filePath)#, apply_value_formats=True, formats_as_category=True)\n",
    "        object_methods = [meta for meta in dir(object) if callable(getattr(object, meta))]\n",
    "        #print('{}'.format('-'*40))\n",
    "        #print('Rows: {}  Cols: {}'.format(df.shape[0], df.shape[1]))\n",
    "\n",
    "        col_names = meta.column_names\n",
    "        col_labels = meta.column_labels\n",
    "        col_names_labels = dict(zip(col_names, col_labels))\n",
    "        #print('Names: {}  Labels: {}'.format(len(col_names), len(col_labels)))\n",
    "        \n",
    "        header = 'Number{0}Year{0}sav file{0}Count of unique values{0}Field (short){0}Field (long)\\n'.format(sep)\n",
    "        for name, label in col_names_labels.items():\n",
    "            unique_cnt = len(df[name].unique())\n",
    "            info_string = '{:<2}  {:<4}  {:<6}  {:<6}  {:<20}  {}'.format(i, year, fname, unique_cnt, name, label)\n",
    "            csv_string = '{1}{0}{2}{0}{3}{0}{4}{0}{5}{0}{6}'.format(sep, i, year, fname, unique_cnt, name, label)\n",
    "            print(csv_string)\n",
    "            with open(outCsv, 'a') as f:\n",
    "                if i==1:\n",
    "                    f.write(header)\n",
    "                f.write(csv_string + '\\n')\n",
    "            i+=1\n",
    "\n",
    "        print('{}\\n'.format('-'*80))\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in Georgia map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Name_sav','Code_sav']\n",
    "#Read geojson using Geopandas\n",
    "gdf = gpd.read_file(c.regions, usecols=fields)\n",
    "gdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at UID to join all tables into one ...scratch that, setup sysschedule to merge region name to all other tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_year = 2018\n",
    "tblList = []\n",
    "sysscheduleCsv = os.path.join(c.outDir, 'sysschedule.csv')\n",
    "indexFile = 'sysschedule.sav'\n",
    "\n",
    "dfRegTbl = pd.read_csv(c.regionLookup)\n",
    "\n",
    "i = 1\n",
    "for stataDir in stataDirs:\n",
    "    year = os.path.basename(stataDir)[:4]\n",
    "    if int(year) != search_year:\n",
    "        continue\n",
    "    print('yr: {}   I want: {}'.format(year, search_year))\n",
    "    \n",
    "    for f in sorted(os.listdir(stataDir)):\n",
    "        filePath = os.path.join(stataDir, f)\n",
    "        tblList.append(filePath)\n",
    "\n",
    "# Read index table (sysschedule), and get UID and Region cols\n",
    "indexTbl = [t for t in tblList if indexFile in t][0]\n",
    "df, meta = prs.read_sav(indexTbl)\n",
    "# replace column names with column labels\n",
    "df.columns = meta.column_labels\n",
    "\n",
    "#print('_' * 80)\n",
    "#print(df.head())\n",
    "#print('_' * 80)\n",
    "#print(dfRegTbl)\n",
    "\n",
    "df = df.merge(dfRegTbl, how='left', left_on='Region', right_on='Code_sav')\n",
    "df = df.drop(['Code_sav'], axis=1)\n",
    "df = df.rename(columns={'Name_sav': 'Region Name'})\n",
    "#print(df.count())\n",
    "print('_' * 80)\n",
    "\n",
    "df.to_csv(sysscheduleCsv, sep='\\t')\n",
    "df.head()\n",
    "\n",
    "#Unique ID of the household in the quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now add Region Name to all tables and substitute full column names for code names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_year = 2018\n",
    "tblList = []\n",
    "sysscheduleCsv = os.path.join(c.outDir, 'sysschedule.csv')\n",
    "joinFld = 'Unique ID of the household in the quarter'\n",
    "joinFldDrop = 'UID_Drop'\n",
    "\n",
    "\n",
    "dfIdx = pd.read_csv(sysscheduleCsv, sep='\\t')\n",
    "dfIdx = dfIdx[['Unique ID of the household in the quarter', \n",
    "               'Unique ID of the household during the whole period',\n",
    "               'Region', \n",
    "               'Region Name']]\n",
    "dfIdx = dfIdx.rename(columns={joinFld : joinFldDrop})\n",
    "#print(dfIdx.head())\n",
    "\n",
    "for stataDir in stataDirs:\n",
    "    year = os.path.basename(stataDir)[:4]\n",
    "    if int(year) != search_year:\n",
    "        continue\n",
    "    print('yr: {}   I want: {}'.format(year, search_year))\n",
    "    \n",
    "    for f in sorted(os.listdir(stataDir)):\n",
    "        filePath = os.path.join(stataDir, f)\n",
    "        tblList.append(filePath)\n",
    "\n",
    "for t in tblList:\n",
    "    outFile = os.path.join(c.outDir, os.path.basename(t).replace('.sav', '.csv'))\n",
    "    if 'sysschedule' in t:\n",
    "        continue\n",
    "    \n",
    "    df, meta = prs.read_sav(t)\n",
    "    # replace column names with column labels\n",
    "    df.columns = meta.column_labels\n",
    "    \n",
    "    if joinFld in meta.column_labels:\n",
    "        df = df.merge(dfIdx, how='left', left_on=joinFld, right_on=joinFldDrop)\n",
    "        df = df.drop([joinFldDrop], axis=1)\n",
    "        df.to_csv(outFile, sep='\\t')\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print('⬇ No UID ⬇')\n",
    "        outFile = outFile.replace('.csv', '_NoUID.csv')\n",
    "        df.to_csv(outFile, sep='\\t') \n",
    "        print(df.head())\n",
    "\n",
    "    print(outFile)\n",
    "    print('_' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
